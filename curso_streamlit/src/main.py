import streamlit as st
import numpy as np
import pandas as pd
import pandas_datareader.data as pdr
from datetime import datetime, timedelta
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import os

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="An√°lise de Regress√£o Linear - BOVESPA",
    page_icon="üìà",
    layout="wide",
    initial_sidebar_state="expanded"
)

# T√≠tulo e descri√ß√£o
st.title("üìà An√°lise de Regress√£o Linear - A√ß√µes Globais/Stooq")
st.markdown("""
Este aplicativo realiza an√°lise completa de regress√£o linear sobre dados de a√ß√µes hist√≥ricos, utilizando dados reais das principais bolsas do mundo via Stooq, sem necessidade de API Key!
Explore diferentes modelos, visualize m√©tricas de performance e entenda os resultados atrav√©s de gr√°ficos explicativos.
""")

@st.cache_data
def carregar_tickers_acoes():
    # Exemplo com algumas a√ß√µes globais e brasileiras (Stooq usa formatos diferentes)
    return [
        "AAPL", "MSFT", "GOOGL", "AMZN", "TSLA", "META", "NFLX", # EUA
        "PETR4.SA", "VALE3.SA", "ITUB4.SA", "BBDC4.SA", "B3SA3.SA", # Brasil
        "SIE.DE", "BMW.DE", "AIR.PA", "MC.PA", "SAN.MC" # Europa: Alemanha(EUA.DE), Fran√ßa, Espanha
    ]

@st.cache_data(ttl=3600)
def carregar_dados_stooq(ticker):
    try:
        # Ajuste datas se necess√°rio
        end = datetime.today()
        start = end - timedelta(days=1800)
        df = pdr.DataReader(ticker, data_source='stooq', start=start, end=end)
    except Exception as e:
        st.error(f"Erro ao baixar dados de {ticker}: {str(e)}")
        return pd.DataFrame()
    if df.empty:
        return pd.DataFrame()
    # Ajusta √≠ndice se necess√°rio (para Streamlit)
    df = df.sort_index()
    # Feature engineering
    df['Dia'] = range(len(df))
    df['Retorno'] = df['Close'].pct_change()
    df['Volume_Norm'] = (df['Volume'] - df['Volume'].mean()) / df['Volume'].std()
    df['Volatilidade'] = df['Retorno'].rolling(window=20).std()
    df['MA7'] = df['Close'].rolling(window=7).mean()
    df['MA21'] = df['Close'].rolling(window=21).mean()
    df['Range'] = df['High'] - df['Low']
    df = df.dropna()
    return df

def treinar_modelos(X_train, y_train, X_test, y_test):
    modelos = {}
    resultados = {}
    # 1. Regress√£o Linear Simples
    lr = LinearRegression()
    lr.fit(X_train, y_train)
    y_pred_lr = lr.predict(X_test)
    modelos['Linear Simples'] = lr
    resultados['Linear Simples'] = {
        'predicoes': y_pred_lr,
        'mse': mean_squared_error(y_test, y_pred_lr),
        'rmse': np.sqrt(mean_squared_error(y_test, y_pred_lr)),
        'mae': mean_absolute_error(y_test, y_pred_lr),
        'r2': r2_score(y_test, y_pred_lr),
        'coeficientes': lr.coef_,
        'intercepto': lr.intercept_
    }
    # 2. Ridge
    ridge = Ridge(alpha=1.0)
    ridge.fit(X_train, y_train)
    y_pred_ridge = ridge.predict(X_test)
    modelos['Ridge (L2)'] = ridge
    resultados['Ridge (L2)'] = {
        'predicoes': y_pred_ridge,
        'mse': mean_squared_error(y_test, y_pred_ridge),
        'rmse': np.sqrt(mean_squared_error(y_test, y_pred_ridge)),
        'mae': mean_absolute_error(y_test, y_pred_ridge),
        'r2': r2_score(y_test, y_pred_ridge),
        'coeficientes': ridge.coef_,
        'intercepto': ridge.intercept_
    }
    # 3. Lasso
    lasso = Lasso(alpha=0.1)
    lasso.fit(X_train, y_train)
    y_pred_lasso = lasso.predict(X_test)
    modelos['Lasso (L1)'] = lasso
    resultados['Lasso (L1)'] = {
        'predicoes': y_pred_lasso,
        'mse': mean_squared_error(y_test, y_pred_lasso),
        'rmse': np.sqrt(mean_squared_error(y_test, y_pred_lasso)),
        'mae': mean_absolute_error(y_test, y_pred_lasso),
        'r2': r2_score(y_test, y_pred_lasso),
        'coeficientes': lasso.coef_,
        'intercepto': lasso.intercept_
    }
    # 4. ElasticNet
    elastic = ElasticNet(alpha=0.1, l1_ratio=0.5)
    elastic.fit(X_train, y_train)
    y_pred_elastic = elastic.predict(X_test)
    modelos['ElasticNet'] = elastic
    resultados['ElasticNet'] = {
        'predicoes': y_pred_elastic,
        'mse': mean_squared_error(y_test, y_pred_elastic),
        'rmse': np.sqrt(mean_squared_error(y_test, y_pred_elastic)),
        'mae': mean_absolute_error(y_test, y_pred_elastic),
        'r2': r2_score(y_test, y_pred_elastic),
        'coeficientes': elastic.coef_,
        'intercepto': elastic.intercept_
    }
    # 5. Polinomial
    poly = PolynomialFeatures(degree=2)
    X_train_poly = poly.fit_transform(X_train)
    X_test_poly = poly.transform(X_test)
    lr_poly = LinearRegression()
    lr_poly.fit(X_train_poly, y_train)
    y_pred_poly = lr_poly.predict(X_test_poly)
    modelos['Polinomial (grau 2)'] = (poly, lr_poly)
    resultados['Polinomial (grau 2)'] = {
        'predicoes': y_pred_poly,
        'mse': mean_squared_error(y_test, y_pred_poly),
        'rmse': np.sqrt(mean_squared_error(y_test, y_pred_poly)),
        'mae': mean_absolute_error(y_test, y_pred_poly),
        'r2': r2_score(y_test, y_pred_poly),
        'coeficientes': lr_poly.coef_,
        'intercepto': lr_poly.intercept_
    }
    return modelos, resultados

# Carregar tickers globais
acoes = carregar_tickers_acoes()

# Sidebar
with st.sidebar:
    st.header("‚öôÔ∏è Configura√ß√µes")
    acao_selecionada = st.selectbox("Escolha uma a√ß√£o", acoes, index=0)
    st.subheader("Divis√£o dos Dados")
    test_size = st.slider("Tamanho do conjunto de teste (%)", 10, 40, 20) / 100
    st.subheader("Features para o Modelo")
    usar_volume = st.checkbox("Usar Volume Normalizado", value=True)
    usar_volatilidade = st.checkbox("Usar Volatilidade", value=True)
    usar_mas = st.checkbox("Usar M√©dias M√≥veis", value=True)
    usar_range = st.checkbox("Usar Range (High-Low)", value=True)

if acao_selecionada:
    dados = carregar_dados_stooq(acao_selecionada)
    if dados.empty:
        st.error("‚ùå N√£o foi poss√≠vel carregar dados para esta a√ß√£o.")
    else:
        features_disponiveis = ['Dia']
        if usar_volume:
            features_disponiveis.append('Volume_Norm')
        if usar_volatilidade:
            features_disponiveis.append('Volatilidade')
        if usar_mas:
            features_disponiveis.extend(['MA7', 'MA21'])
        if usar_range:
            features_disponiveis.append('Range')
        X = dados[features_disponiveis].values
        y = dados['Close'].values
        # Dividir dados
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, shuffle=False
        )
        # Normalizar features
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        # Treinar modelos
        modelos, resultados = treinar_modelos(X_train_scaled, y_train, X_test_scaled, y_test)
        
        # Criar abas
        tab1, tab2, tab3, tab4 = st.tabs([
            "üìä Vis√£o Geral", 
            "üîç An√°lise dos Modelos", 
            "üìà Visualiza√ß√µes", 
            "üìö Documenta√ß√£o"
        ])
        
        # TAB 1: VIS√ÉO GERAL
        with tab1:
            st.header("Vis√£o Geral dos Dados e Modelos")
            
            # Informa√ß√£o sobre fonte dos dados
            if os.path.exists(f"cache_cotacoes/{acao_selecionada}_cotacoes.csv"):
                st.info("üìÅ Dados carregados do cache local")
            else:
                st.warning("üîÑ Dados demonstrativos sendo utilizados devido a limita√ß√µes da API")
            
            # M√©tricas principais
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Total de Observa√ß√µes", len(dados))
                st.metric("Dados de Treino", len(X_train))
            
            with col2:
                st.metric("Dados de Teste", len(X_test))
                st.metric("N√∫mero de Features", X.shape[1])
            
            with col3:
                st.metric("Pre√ßo M√≠nimo", f"R$ {dados['Close'].min():.2f}")
                st.metric("Pre√ßo M√°ximo", f"R$ {dados['Close'].max():.2f}")
            
            with col4:
                st.metric("Pre√ßo M√©dio", f"R$ {dados['Close'].mean():.2f}")
                st.metric("Desvio Padr√£o", f"R$ {dados['Close'].std():.2f}")
            
            # Gr√°fico de pre√ßo hist√≥rico
            st.subheader("Hist√≥rico de Pre√ßos")
            fig, ax = plt.subplots(figsize=(12, 6))
            ax.plot(dados.index, dados['Close'], label='Pre√ßo de Fechamento', linewidth=2)
            
            # Destacar divis√£o treino/teste
            split_date = dados.index[len(X_train)]
            ax.axvline(x=split_date, color='red', linestyle='--', label='Divis√£o Treino/Teste')
            
            ax.set_xlabel('Data', fontsize=12)
            ax.set_ylabel('Pre√ßo (R$)', fontsize=12)
            ax.set_title(f'Hist√≥rico de Pre√ßos - {acao_selecionada}', fontsize=14)
            ax.legend()
            ax.grid(True, alpha=0.3)
            st.pyplot(fig)
            
            # Compara√ß√£o de m√©tricas
            st.subheader("Compara√ß√£o de Performance dos Modelos")
            
            metricas_df = pd.DataFrame({
                'Modelo': list(resultados.keys()),
                'R¬≤ Score': [resultados[m]['r2'] for m in resultados],
                'RMSE': [resultados[m]['rmse'] for m in resultados],
                'MAE': [resultados[m]['mae'] for m in resultados],
                'MSE': [resultados[m]['mse'] for m in resultados]
            })
            
            # Destacar melhor modelo
            melhor_modelo = metricas_df.loc[metricas_df['R¬≤ Score'].idxmax(), 'Modelo']
            st.success(f"üèÜ Melhor Modelo (maior R¬≤): **{melhor_modelo}**")
            
            st.dataframe(
                metricas_df.style.highlight_max(axis=0, subset=['R¬≤ Score'], color='lightgreen')
                                .highlight_min(axis=0, subset=['RMSE', 'MAE', 'MSE'], color='lightgreen')
                                .format({'R¬≤ Score': '{:.4f}', 'RMSE': '{:.2f}', 'MAE': '{:.2f}', 'MSE': '{:.2f}'})
            )
        
        # TAB 2: AN√ÅLISE DOS MODELOS
        with tab2:
            st.header("An√°lise Detalhada dos Modelos")
            
            modelo_analise = st.selectbox("Selecione o modelo para an√°lise", list(resultados.keys()))
            
            resultado = resultados[modelo_analise]
            
            # M√©tricas do modelo selecionado
            st.subheader(f"M√©tricas - {modelo_analise}")
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("R¬≤ Score", f"{resultado['r2']:.4f}")
                with st.expander("üìñ O que √© R¬≤ Score?"):
                    st.markdown("""
                    **R¬≤ (Coeficiente de Determina√ß√£o)** mede a propor√ß√£o da vari√¢ncia na vari√°vel dependente 
                    que √© previs√≠vel a partir das vari√°veis independentes.
                    
                    - **R¬≤ = 1**: Modelo perfeito
                    - **R¬≤ = 0**: Modelo n√£o explica a vari√¢ncia
                    - **R¬≤ < 0**: Modelo pior que a m√©dia
                    
                    **Interpreta√ß√£o**: Um R¬≤ de 0.85 significa que 85% da varia√ß√£o nos pre√ßos √© explicada pelo modelo.
                    """)
            
            with col2:
                st.metric("RMSE", f"{resultado['rmse']:.2f}")
                with st.expander("üìñ O que √© RMSE?"):
                    st.markdown("""
                    **RMSE (Root Mean Squared Error)** √© a raiz quadrada da m√©dia dos erros ao quadrado.
                    
                    - Penaliza erros maiores mais fortemente
                    - Mesma unidade da vari√°vel target (R$)
                    - Quanto menor, melhor
                    
                    **Interpreta√ß√£o**: RMSE de 5.0 significa erro m√©dio de R$ 5,00 nas previs√µes.
                    """)
            
            with col3:
                st.metric("MAE", f"{resultado['mae']:.2f}")
                with st.expander("üìñ O que √© MAE?"):
                    st.markdown("""
                    **MAE (Mean Absolute Error)** √© a m√©dia dos valores absolutos dos erros.
                    
                    - Tratamento linear dos erros
                    - Mesma unidade da vari√°vel target (R$)
                    - Mais robusto a outliers que RMSE
                    
                    **Interpreta√ß√£o**: MAE de 3.5 significa erro m√©dio absoluto de R$ 3,50.
                    """)
            
            with col4:
                st.metric("MSE", f"{resultado['mse']:.2f}")
                with st.expander("üìñ O que √© MSE?"):
                    st.markdown("""
                    **MSE (Mean Squared Error)** √© a m√©dia dos erros ao quadrado.
                    
                    - Penaliza erros grandes
                    - Sempre positivo
                    - Sens√≠vel a outliers
                    
                    **Interpreta√ß√£o**: Quanto menor, melhor o ajuste do modelo.
                    """)
            
            # Gr√°fico de Predi√ß√µes vs Real
            st.subheader("Predi√ß√µes vs Valores Reais")
            
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))
            
            # Scatter plot
            ax1.scatter(y_test, resultado['predicoes'], alpha=0.6, edgecolors='k')
            ax1.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 
                    'r--', lw=2, label='Predi√ß√£o Perfeita')
            ax1.set_xlabel('Valores Reais (R$)', fontsize=11)
            ax1.set_ylabel('Predi√ß√µes (R$)', fontsize=11)
            ax1.set_title(f'{modelo_analise} - Predi√ß√µes vs Real', fontsize=12)
            ax1.legend()
            ax1.grid(True, alpha=0.3)
            
            # Linha do tempo
            ax2.plot(range(len(y_test)), y_test, label='Real', linewidth=2)
            ax2.plot(range(len(y_test)), resultado['predicoes'], 
                    label='Predi√ß√£o', linewidth=2, alpha=0.7)
            ax2.set_xlabel('Observa√ß√£o', fontsize=11)
            ax2.set_ylabel('Pre√ßo (R$)', fontsize=11)
            ax2.set_title(f'{modelo_analise} - S√©rie Temporal', fontsize=12)
            ax2.legend()
            ax2.grid(True, alpha=0.3)
            
            plt.tight_layout()
            st.pyplot(fig)
            
            # An√°lise de Res√≠duos
            st.subheader("An√°lise de Res√≠duos")
            
            residuos = y_test - resultado['predicoes']
            
            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(14, 10))
            
            # 1. Histograma dos res√≠duos
            ax1.hist(residuos, bins=30, edgecolor='black', alpha=0.7)
            ax1.axvline(x=0, color='red', linestyle='--')
            ax1.set_xlabel('Res√≠duos (R$)', fontsize=11)
            ax1.set_ylabel('Frequ√™ncia', fontsize=11)
            ax1.set_title('Distribui√ß√£o dos Res√≠duos', fontsize=12)
            ax1.grid(True, alpha=0.3)
            
            # 2. Q-Q Plot
            stats.probplot(residuos, dist="norm", plot=ax2)
            ax2.set_title('Q-Q Plot', fontsize=12)
            ax2.grid(True, alpha=0.3)
            
            # 3. Res√≠duos vs Valores Preditos
            ax3.scatter(resultado['predicoes'], residuos, alpha=0.6, edgecolors='k')
            ax3.axhline(y=0, color='red', linestyle='--')
            ax3.set_xlabel('Valores Preditos (R$)', fontsize=11)
            ax3.set_ylabel('Res√≠duos (R$)', fontsize=11)
            ax3.set_title('Res√≠duos vs Predi√ß√µes', fontsize=12)
            ax3.grid(True, alpha=0.3)
            
            # 4. Res√≠duos ao longo do tempo
            ax4.plot(range(len(residuos)), residuos, alpha=0.7)
            ax4.axhline(y=0, color='red', linestyle='--')
            ax4.set_xlabel('Observa√ß√£o', fontsize=11)
            ax4.set_ylabel('Res√≠duos (R$)', fontsize=11)
            ax4.set_title('Res√≠duos ao Longo do Tempo', fontsize=12)
            ax4.grid(True, alpha=0.3)
            
            plt.tight_layout()
            st.pyplot(fig)
            
            with st.expander("üìñ Como interpretar a An√°lise de Res√≠duos?"):
                st.markdown("""
                A **An√°lise de Res√≠duos** verifica as suposi√ß√µes da regress√£o linear:
                
                1. **Distribui√ß√£o dos Res√≠duos**: Deve ser aproximadamente normal (formato de sino)
                2. **Q-Q Plot**: Pontos devem seguir a linha diagonal (normalidade)
                3. **Res√≠duos vs Predi√ß√µes**: Devem estar distribu√≠dos aleatoriamente em torno de zero (homocedasticidade)
                4. **Res√≠duos ao Longo do Tempo**: N√£o deve haver padr√µes (independ√™ncia)
                
                **Problemas comuns:**
                - Padr√£o em formato de funil ‚Üí heterocedasticidade
                - Padr√µes sistem√°ticos ‚Üí modelo n√£o linear adequado
                - Outliers ‚Üí observa√ß√µes at√≠picas influenciando o modelo
                """)
            
            # Coeficientes do modelo
            if modelo_analise != 'Polinomial (grau 2)':
                st.subheader("Coeficientes do Modelo")
                
                coef_df = pd.DataFrame({
                    'Feature': features_disponiveis,
                    'Coeficiente': resultado['coeficientes']
                })
                coef_df['Import√¢ncia Abs'] = np.abs(coef_df['Coeficiente'])
                coef_df = coef_df.sort_values('Import√¢ncia Abs', ascending=False)
                
                st.dataframe(coef_df.style.format({'Coeficiente': '{:.4f}', 'Import√¢ncia Abs': '{:.4f}'}))
                
                # Gr√°fico de import√¢ncia
                fig, ax = plt.subplots(figsize=(10, 5))
                colors = ['green' if x > 0 else 'red' for x in coef_df['Coeficiente']]
                ax.barh(coef_df['Feature'], coef_df['Coeficiente'], color=colors, alpha=0.7)
                ax.axvline(x=0, color='black', linestyle='-', linewidth=0.8)
                ax.set_xlabel('Valor do Coeficiente', fontsize=11)
                ax.set_title('Import√¢ncia das Features', fontsize=12)
                ax.grid(True, alpha=0.3, axis='x')
                st.pyplot(fig)
                
                with st.expander("üìñ Como interpretar os Coeficientes?"):
                    st.markdown("""
                    Os **Coeficientes** indicam a rela√ß√£o entre cada feature e o pre√ßo:
                    
                    - **Positivo**: Aumento na feature ‚Üí aumento no pre√ßo
                    - **Negativo**: Aumento na feature ‚Üí diminui√ß√£o no pre√ßo
                    - **Magnitude**: Quanto maior (em m√≥dulo), maior o impacto
                    
                    **Importante**: Os coeficientes s√£o para features normalizadas, 
                    ent√£o representam o impacto de uma mudan√ßa de 1 desvio padr√£o na feature.
                    """)
        
        # TAB 3: VISUALIZA√á√ïES
        with tab3:
            st.header("Visualiza√ß√µes Comparativas")
            
            # Compara√ß√£o de todos os modelos
            st.subheader("Compara√ß√£o Visual dos Modelos")
            
            fig, axes = plt.subplots(2, 3, figsize=(16, 10))
            axes = axes.flatten()
            
            for idx, (nome, resultado) in enumerate(resultados.items()):
                ax = axes[idx]
                ax.scatter(y_test, resultado['predicoes'], alpha=0.6, edgecolors='k', s=30)
                ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 
                       'r--', lw=2)
                ax.set_xlabel('Real (R$)', fontsize=10)
                ax.set_ylabel('Predi√ß√£o (R$)', fontsize=10)
                ax.set_title(f'{nome}\nR¬≤={resultado["r2"]:.4f}', fontsize=11)
                ax.grid(True, alpha=0.3)
            
            # Remover subplot extra
            fig.delaxes(axes[-1])
            
            plt.tight_layout()
            st.pyplot(fig)
            
            # Gr√°fico de barras das m√©tricas
            st.subheader("Compara√ß√£o de M√©tricas")
            
            fig, axes = plt.subplots(2, 2, figsize=(14, 10))
            
            modelos_nomes = list(resultados.keys())
            
            # R¬≤
            r2_scores = [resultados[m]['r2'] for m in modelos_nomes]
            axes[0, 0].bar(modelos_nomes, r2_scores, color='steelblue', alpha=0.7)
            axes[0, 0].set_ylabel('R¬≤ Score', fontsize=11)
            axes[0, 0].set_title('R¬≤ Score por Modelo', fontsize=12)
            axes[0, 0].tick_params(axis='x', rotation=45)
            axes[0, 0].grid(True, alpha=0.3, axis='y')
            
            # RMSE
            rmse_scores = [resultados[m]['rmse'] for m in modelos_nomes]
            axes[0, 1].bar(modelos_nomes, rmse_scores, color='coral', alpha=0.7)
            axes[0, 1].set_ylabel('RMSE (R$)', fontsize=11)
            axes[0, 1].set_title('RMSE por Modelo', fontsize=12)
            axes[0, 1].tick_params(axis='x', rotation=45)
            axes[0, 1].grid(True, alpha=0.3, axis='y')
            
            # MAE
            mae_scores = [resultados[m]['mae'] for m in modelos_nomes]
            axes[1, 0].bar(modelos_nomes, mae_scores, color='lightgreen', alpha=0.7)
            axes[1, 0].set_ylabel('MAE (R$)', fontsize=11)
            axes[1, 0].set_title('MAE por Modelo', fontsize=12)
            axes[1, 0].tick_params(axis='x', rotation=45)
            axes[1, 0].grid(True, alpha=0.3, axis='y')
            
            # MSE
            mse_scores = [resultados[m]['mse'] for m in modelos_nomes]
            axes[1, 1].bar(modelos_nomes, mse_scores, color='mediumpurple', alpha=0.7)
            axes[1, 1].set_ylabel('MSE', fontsize=11)
            axes[1, 1].set_title('MSE por Modelo', fontsize=12)
            axes[1, 1].tick_params(axis='x', rotation=45)
            axes[1, 1].grid(True, alpha=0.3, axis='y')
            
            plt.tight_layout()
            st.pyplot(fig)
            
            # Boxplot dos erros
            st.subheader("Distribui√ß√£o dos Erros por Modelo")
            
            fig, ax = plt.subplots(figsize=(12, 6))
            
            erros_modelos = [np.abs(y_test - resultados[m]['predicoes']) for m in modelos_nomes]
            
            bp = ax.boxplot(erros_modelos, labels=modelos_nomes, patch_artist=True)
            for patch in bp['boxes']:
                patch.set_facecolor('lightblue')
            
            ax.set_ylabel('Erro Absoluto (R$)', fontsize=11)
            ax.set_title('Distribui√ß√£o dos Erros Absolutos por Modelo', fontsize=12)
            ax.tick_params(axis='x', rotation=45)
            ax.grid(True, alpha=0.3, axis='y')
            
            st.pyplot(fig)
        
        # TAB 4: DOCUMENTA√á√ÉO
        with tab4:
            st.header("üìö Documenta√ß√£o e Conceitos")
            
            st.markdown("""
            ## Modelos Implementados
            
            Este aplicativo implementa 5 diferentes t√©cnicas de regress√£o linear:
            """)
            
            with st.expander("1Ô∏è‚É£ Regress√£o Linear Simples"):
                st.markdown("""
                ### Regress√£o Linear Simples
                
                **Descri√ß√£o**: M√©todo cl√°ssico que encontra a melhor linha reta para ajustar os dados.
                
                **F√≥rmula**: y = Œ≤‚ÇÄ + Œ≤‚ÇÅx‚ÇÅ + Œ≤‚ÇÇx‚ÇÇ + ... + Œ≤‚Çôx‚Çô + Œµ
                
                **Caracter√≠sticas**:
                - M√©todo dos M√≠nimos Quadrados Ordin√°rios (OLS)
                - Minimiza a soma dos quadrados dos res√≠duos
                - Sem regulariza√ß√£o
                - Pode sofrer de overfitting com muitas features
                
                **Quando usar**: 
                - Rela√ß√£o linear clara entre vari√°veis
                - N√∫mero de features n√£o √© muito grande
                - N√£o h√° multicolinearidade severa
                """)
            
            with st.expander("2Ô∏è‚É£ Regress√£o Ridge (L2)"):
                st.markdown("""
                ### Regress√£o Ridge (L2 Regularization)
                
                **Descri√ß√£o**: Adiciona penaliza√ß√£o L2 (soma dos quadrados dos coeficientes) √† fun√ß√£o de custo.
                
                **F√≥rmula**: y = Œ≤‚ÇÄ + Œ≤‚ÇÅx‚ÇÅ + Œ≤‚ÇÇx‚ÇÇ + ... + Œ≤‚Çôx‚Çô + Œµ + Œ±‚àëŒ≤·µ¢¬≤
                
                **Caracter√≠sticas**:
                - Reduz coeficientes mas n√£o os zera
                - Lida bem com multicolinearidade
                - Par√¢metro Œ± controla a regulariza√ß√£o
                - Preserva todas as features
                
                **Quando usar**:
                - Muitas features correlacionadas
                - Suspeita de overfitting
                - Todas as features podem ser relevantes
                """)
            
            with st.expander("3Ô∏è‚É£ Regress√£o Lasso (L1)"):
                st.markdown("""
                ### Regress√£o Lasso (L1 Regularization)
                
                **Descri√ß√£o**: Adiciona penaliza√ß√£o L1 (soma dos valores absolutos dos coeficientes) √† fun√ß√£o de custo.
                
                **F√≥rmula**: y = Œ≤‚ÇÄ + Œ≤‚ÇÅx‚ÇÅ + Œ≤‚ÇÇx‚ÇÇ + ... + Œ≤‚Çôx‚Çô + Œµ + Œ±‚àë|Œ≤·µ¢|
                
                **Caracter√≠sticas**:
                - Pode zerar coeficientes (sele√ß√£o autom√°tica de features)
                - Produz modelos esparsos
                - √ötil para sele√ß√£o de features
                - Menos est√°vel que Ridge
                
                **Quando usar**:
                - Muitas features irrelevantes
                - Necessidade de sele√ß√£o autom√°tica de features
                - Interpretabilidade √© importante
                """)
            
            with st.expander("4Ô∏è‚É£ ElasticNet (L1 + L2)"):
                st.markdown("""
                ### ElasticNet (L1 + L2 Regularization)
                
                **Descri√ß√£o**: Combina penaliza√ß√µes L1 e L2, balanceando as vantagens de ambas.
                
                **F√≥rmula**: y = Œ≤‚ÇÄ + Œ≤‚ÇÅx‚ÇÅ + ... + Œ≤‚Çôx‚Çô + Œµ + Œ±[œÅ‚àë|Œ≤·µ¢| + (1-œÅ)‚àëŒ≤·µ¢¬≤]
                
                **Caracter√≠sticas**:
                - Combina sele√ß√£o de features (L1) e estabilidade (L2)
                - Dois par√¢metros: Œ± (regulariza√ß√£o) e œÅ (balanceamento L1/L2)
                - Mais flex√≠vel que Ridge ou Lasso isoladamente
                - Funciona bem com grupos de features correlacionadas
                
                **Quando usar**:
                - Grupos de features correlacionadas
                - Necessidade de sele√ß√£o de features e estabilidade
                - Quando nem Ridge nem Lasso funcionam bem sozinhos
                """)
            
            with st.expander("5Ô∏è‚É£ Regress√£o Polinomial"):
                st.markdown("""
                ### Regress√£o Polinomial
                
                **Descri√ß√£o**: Estende a regress√£o linear criando features polinomiais das vari√°veis originais.
                
                **Exemplo (grau 2)**: y = Œ≤‚ÇÄ + Œ≤‚ÇÅx‚ÇÅ + Œ≤‚ÇÇx‚ÇÇ + Œ≤‚ÇÉx‚ÇÅ¬≤ + Œ≤‚ÇÑx‚ÇÇ¬≤ + Œ≤‚ÇÖx‚ÇÅx‚ÇÇ + Œµ
                
                **Caracter√≠sticas**:
                - Captura rela√ß√µes n√£o-lineares
                - Aumenta significativamente o n√∫mero de features
                - Risco alto de overfitting
                - Pode modelar curvas complexas
                
                **Quando usar**:
                - Rela√ß√µes n√£o-lineares evidentes nos dados
                - Poucos dados de treinamento (evitar graus altos)
                - Combinado com regulariza√ß√£o para evitar overfitting
                """)
            
            # ... resto da documenta√ß√£o igual ao c√≥digo anterior ...
            
            st.markdown("""
            ## Sobre os Dados
            
            ### Fonte dos Dados
            - **Prim√°ria**: Yahoo Finance via yfinance
            - **Cache Local**: Dados salvos ap√≥s primeiro download
            - **Fallback**: Dados sint√©ticos quando API n√£o funciona
            
            ### Tratamento de Erros
            - Sistema de retry com delay progressivo
            - Headers customizados para evitar bloqueio
            - Cache local para reduzir chamadas √† API
            - Dados demonstrativos como √∫ltima op√ß√£o
            
            ### Limita√ß√µes
            - Dados podem estar desatualizados devido a limita√ß√µes da API
            - Dados sint√©ticos s√£o apenas para demonstra√ß√£o
            - Performance real pode variar com dados atualizados
            """)

# Rodap√©
st.markdown("---")
st.markdown("""
**Desenvolvido por Bruno Galv√£o**  
**An√°lise de Regress√£o Linear para A√ß√µes da BOVESPA**  
*Este aplicativo √© para fins educacionais e de an√°lise. N√£o constitui recomenda√ß√£o de investimento.*

‚ö†Ô∏è **Nota sobre Dados**: Devido a limita√ß√µes recentes da API do Yahoo Finance, o aplicativo pode utilizar dados em cache ou demonstrativos.
""")
